{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8b46SWUvuGx"
      },
      "source": [
        "# Using Jupyter Notebooks\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk spacy gensim pandas scikit-learn\n",
        "\n",
        "#NLTK (Natural Language Toolkit):\n",
        "\n",
        "#A comprehensive library for working with human language data (text) in Python. NLTK provides tools for text processing, including tokenization, parsing, stemming, tagging, and semantic reasoning, and is often used in natural language processing (NLP) tasks. It includes a wide array of corpora and lexical resources, such as WordNet, which are helpful in linguistics and language analysis.\n",
        "#spaCy:\n",
        "\n",
        "#An advanced NLP library designed for fast and efficient processing of large volumes of text. SpaCy offers high-performance solutions for tokenization, part-of-speech tagging, named entity recognition (NER), dependency parsing, and word vector generation. It’s widely used for tasks requiring speed and accuracy in text processing, making it popular for building NLP models in production environments.\n",
        "#Gensim:\n",
        "\n",
        "#A Python library for topic modeling, document similarity analysis, and text mining. Gensim specializes in unsupervised and large-scale machine learning, especially in handling text data. It provides implementations for popular algorithms like Word2Vec, Doc2Vec, and Latent Dirichlet Allocation (LDA), allowing users to efficiently find patterns and relationships within text data.\n",
        "#Pandas:\n",
        "\n",
        "#A powerful and flexible data manipulation library for Python, essential for data analysis and data wrangling tasks. Pandas provides two primary data structures: DataFrame and Series, which allow for easy data manipulation, filtering, aggregation, and analysis. It is particularly useful for working with structured data, enabling data scientists and analysts to handle datasets in a tabular format similar to SQL or Excel.\n",
        "#scikit-learn:\n",
        "\n",
        "#A machine learning library built on top of NumPy, SciPy, and matplotlib, which provides simple and efficient tools for predictive data analysis. Scikit-learn offers a range of supervised and unsupervised learning algorithms, including classification, regression, clustering, and dimensionality reduction. It is designed for rapid prototyping and is widely used for implementing machine learning models in research and production.\n",
        "\n"
      ],
      "metadata": {
        "id": "Osoh-IpZwuYp",
        "outputId": "f3b09eea-cb81-4309-eb59-bee77a20fb1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.2)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.1)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ3M5cCUN6i8"
      },
      "source": [
        "##Introduction\n",
        "Jupyter notebooks is an open-source web-based Python editor which runs in your browser. It allows a combination of text written in a html-like format known as \"markdown\", such as the block of text you're reading right now, and inline code, tools and outputs such as this one:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt') # Download the Punkt tokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sentence = \"Hello, world! This is NLP.\"\n",
        "tokens = word_tokenize(sentence)\n",
        "print(tokens) # Output: ['Hello', ',', 'world', '!', 'This', 'is','NLP', '.']\n",
        "\n",
        "#nltk:\n",
        "\n",
        "#Short for Natural Language Toolkit, NLTK is a Python library that provides tools for text processing, including tokenization, parsing, stemming, and various NLP tasks. It also includes access to large lexical resources like WordNet.\n",
        "#download:\n",
        "\n",
        "#A method used here to download NLTK's \"punkt\" tokenizer. The download function in NLTK allows you to fetch various text-processing resources like tokenizers, corpora, and models directly from the NLTK server.\n",
        "#punkt:\n",
        "\n",
        "#A pre-trained tokenizer model in NLTK designed for sentence and word tokenization. It helps break down sentences into individual tokens, handling punctuation and other language-specific tokenization rules.\n",
        "tokenize:\n",
        "\n",
        "#A process in NLP to split text into smaller components called tokens, such as words or sentences. Tokenization is essential for preparing raw text for further analysis or model training.\n",
        "word_tokenize:\n",
        "\n",
        "#A specific tokenizer in NLTK used to break down a sentence into individual words and punctuation marks. It applies the Punkt tokenizer model to split text at word boundaries.\n",
        "#sentence:\n",
        "\n",
        "#In this code, sentence is a variable holding a string of text to be tokenized. In NLP, a sentence typically refers to a sequence of words that form a complete thought and is used as a unit of analysis.\n",
        "tokens:\n",
        "\n",
        "#A list that stores the individual words and punctuation marks obtained after tokenizing the sentence. In NLP, tokens are the basic units of analysis, representing each word, symbol, or punctuation mark separately."
      ],
      "metadata": {
        "id": "BqtrcvM2xL5h",
        "outputId": "3aa9ee3a-c602-4543-d5dc-c291f79ac0fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '!', 'This', 'is', 'NLP', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GDTYoruGxMEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mks2EtD4xMMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt') # Download the Punkt tokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "# nltk:\n",
        "# Short for Natural Language Toolkit, nltk is a powerful Python library for natural language processing (NLP).\n",
        "# It provides tools for processing text data, such as tokenization, stemming, and tagging,\n",
        "# and includes access to resources like WordNet for linguistic analysis.\n",
        "#\n",
        "# download:\n",
        "# The download function in nltk allows users to fetch resources, such as tokenizers, corpora,\n",
        "# and models, directly from NLTK’s server. Here, it’s downloading the \"punkt\" tokenizer.\n",
        "#\n",
        "# punkt:\n",
        "# \"Punkt\" is a pre-trained tokenizer model within NLTK that’s used for sentence and word tokenization.\n",
        "# It was specifically trained to handle common punctuation and tokenization rules, making it useful\n",
        "# for accurately splitting sentences and words in various languages.\n",
        "#\n",
        "# tokenize:\n",
        "# Tokenization is the process of dividing text into smaller units, such as words or sentences,\n",
        "# known as tokens. This is a crucial step in NLP as it allows text to be processed and analyzed more effectively.\n",
        "#\n",
        "# word_tokenize:\n",
        "# A specific function in NLTK’s tokenize module that splits a given sentence or text into individual\n",
        "# words and punctuation marks. word_tokenize uses the Punkt tokenizer model to segment the text at word boundaries.\n"
      ],
      "metadata": {
        "id": "AmQQ5MkGxMQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in\n",
        "stop_words]\n",
        "print(filtered_tokens)\n",
        "\n",
        "# stopwords:\n",
        "# A predefined list of commonly used words (like \"and\", \"the\", \"is\") in a language\n",
        "# that are often removed from text during processing. Stopwords typically carry\n",
        "# little meaning and do not contribute significantly to the context of the data.\n",
        "#\n",
        "# nltk:\n",
        "# Short for Natural Language Toolkit, nltk is a Python library that provides tools\n",
        "# and resources for processing human language data (text). It includes modules for\n",
        "# text classification, tokenization, stemming, tagging, parsing, and semantic reasoning.\n",
        "#\n",
        "# download:\n",
        "# A method in NLTK used to retrieve various resources such as corpora and models\n",
        "# from the NLTK server. Here, it downloads the dataset of stop words.\n",
        "#\n",
        "# set():\n",
        "# A built-in Python data structure that creates an unordered collection of unique\n",
        "# elements. It is useful for membership testing and eliminating duplicate entries from a list.\n",
        "#\n",
        "# words():\n",
        "# A function from the stopwords module in NLTK that returns a list of stop words\n",
        "# for a specified language. In this case, it retrieves the list for English.\n",
        "#\n",
        "# filtered_tokens:\n",
        "# A list that stores tokens after removing stop words. This variable holds the final\n",
        "# result, consisting of words that contribute more meaning to the text.\n",
        "#\n",
        "# tokens:\n",
        "# A list of words or tokens derived from an initial text, which can include words\n",
        "# and punctuation. This variable is expected to be defined earlier in the code (from the tokenization step).\n",
        "\n"
      ],
      "metadata": {
        "id": "AYwn_9rSxMTx",
        "outputId": "5f00ab3b-a6ec-4e77-8681-9dd84c866bfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '!', 'NLP', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "ps = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(ps.stem(\"faster\")) # Output: run\n",
        "print(lemmatizer.lemmatize(\"faster\")) # Output: running (more context needed for lemmatization)\n",
        "\n",
        "# PorterStemmer:\n",
        "# A class in NLTK used for stemming, which reduces words to their root or base form\n",
        "# by removing prefixes and suffixes. The Porter algorithm is one of the most commonly\n",
        "# used stemming algorithms.\n",
        "#\n",
        "# WordNetLemmatizer:\n",
        "# A class in NLTK that performs lemmatization, which is the process of converting\n",
        "# a word to its base form (lemma). Unlike stemming, lemmatization considers the\n",
        "# context of the word to return a valid root form.\n",
        "#\n",
        "# download:\n",
        "# A method in NLTK used to retrieve resources such as corpora and models from\n",
        "# the NLTK server. In this case, it downloads the WordNet database, which is\n",
        "# essential for lemmatization.\n",
        "#\n",
        "# stem():\n",
        "# A method in the PorterStemmer class that takes a word as input and returns\n",
        "# its stemmed version. The process may not always yield a meaningful root form,\n",
        "# especially for irregular words.\n",
        "#\n",
        "# lemmatize():\n",
        "# A method in the WordNetLemmatizer class that converts a word into its lemma\n",
        "# based on its intended meaning. Additional context (like part of speech) can\n",
        "# enhance its accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "z-jisxs7xMWw",
        "outputId": "25832466-57cd-46fc-dd47-19203ff1ce20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "faster\n",
            "faster\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "\n",
        "# pandas:\n",
        "# A powerful Python library used for data manipulation and analysis, particularly\n",
        "# useful for working with structured data like tables (DataFrames).\n",
        "#\n",
        "# nltk:\n",
        "# Short for Natural Language Toolkit, nltk is a Python library providing tools\n",
        "# for natural language processing (NLP), including text processing, tokenization,\n",
        "# and linguistic analysis.\n",
        "#\n",
        "# train_test_split:\n",
        "# A function in the sklearn.model_selection module that divides a dataset into\n",
        "# training and testing subsets, helping in model evaluation by ensuring that\n",
        "# the model is tested on unseen data.\n",
        "#\n",
        "# CountVectorizer:\n",
        "# A class in the sklearn.feature_extraction.text module that converts a\n",
        "# collection of text documents into a matrix of token counts, facilitating the\n",
        "# transformation of text data into a numerical format for machine learning.\n",
        "#\n",
        "# MultinomialNB:\n",
        "# A class from the sklearn.naive_bayes module that implements the Naive Bayes\n",
        "# algorithm for classification tasks, particularly effective for discrete\n",
        "# features like word counts in text classification.\n",
        "#\n",
        "# metrics:\n",
        "# A module in sklearn that provides functions to evaluate the performance of\n",
        "# machine learning models, including accuracy, precision, recall, and F1-score.\n"
      ],
      "metadata": {
        "id": "V8_SafrRxMZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        " 'text': [\n",
        " 'I love this movie!',\n",
        " 'This was a terrible movie.',\n",
        " 'I really enjoyed the film.',\n",
        " 'Worst experience ever.',\n",
        " 'It was fantastic!',\n",
        " 'Not worth the time.',\n",
        " 'Absolutely amazing!',\n",
        " 'It was okay, not great.',\n",
        " 'I hate this film.',\n",
        " 'Best movie ever!'\n",
        " ],\n",
        " 'sentiment': [\n",
        " 'negative',\n",
        " 'positive',\n",
        " 'negative',\n",
        " 'positive',\n",
        " 'negative',\n",
        " 'positive',\n",
        " 'negative',\n",
        " 'neutral',\n",
        " 'negative',\n",
        " 'positive'\n",
        " ]\n",
        "}\n",
        "\n",
        "# data:\n",
        "# A variable name used to store structured information in Python, often in the form of dictionaries, lists, or other data types.\n",
        "#\n",
        "# dictionary:\n",
        "# A built-in data type in Python that stores data in key-value pairs, allowing for efficient data retrieval.\n",
        "#\n",
        "# text:\n",
        "# A key in the dictionary representing a collection of textual data, such as user reviews or comments.\n",
        "#\n",
        "# sentiment:\n",
        "# A key in the dictionary that categorizes the emotional tone expressed in the corresponding text samples (e.g., positive, negative, neutral).\n",
        "#\n",
        "# list:\n",
        "# A built-in data structure in Python that holds an ordered collection of items, which can be of different types.\n"
      ],
      "metadata": {
        "id": "9R-6RevNxMca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data)\n",
        "\n",
        "# df:\n",
        "# A variable name used to store a DataFrame object, which is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure in pandas.\n",
        "#\n",
        "# pd:\n",
        "# An alias commonly used for the pandas library in Python, allowing for easier access to its functions and classes.\n",
        "#\n",
        "# DataFrame:\n",
        "# A two-dimensional, size-mutable, and potentially heterogeneous tabular data structure in pandas, with labeled axes (rows and columns), useful for data manipulation and analysis.\n",
        "#\n",
        "# data:\n",
        "# A variable containing structured information (e.g., dictionary) that is being converted into a DataFrame format.\n"
      ],
      "metadata": {
        "id": "nM7-QMPaxMfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "WuzprVcA2za-",
        "outputId": "449ff830-3615-4185-f61f-ff2e3170814e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         text sentiment\n",
            "0          I love this movie!  negative\n",
            "1  This was a terrible movie.  positive\n",
            "2  I really enjoyed the film.  negative\n",
            "3      Worst experience ever.  positive\n",
            "4           It was fantastic!  negative\n",
            "5         Not worth the time.  positive\n",
            "6         Absolutely amazing!  negative\n",
            "7     It was okay, not great.   neutral\n",
            "8           I hate this film.  negative\n",
            "9            Best movie ever!  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text']\n",
        "y = df['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)\n",
        "# Vectorize the text\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# X:\n",
        "# A variable representing the input features (text data) for the model, extracted from the DataFrame.\n",
        "#\n",
        "# y:\n",
        "# A variable representing the target labels (sentiment) for the model, extracted from the DataFrame.\n",
        "#\n",
        "# X_train, X_test:\n",
        "# Variables that store the training and testing subsets of the input features, respectively.\n",
        "#\n",
        "# y_train, y_test:\n",
        "# Variables that store the training and testing subsets of the target labels, respectively.\n",
        "#\n",
        "# train_test_split:\n",
        "# A function from sklearn that splits arrays or matrices into random train and test subsets, facilitating model evaluation.\n",
        "#\n",
        "# test_size:\n",
        "# A parameter that specifies the proportion of the dataset to include in the test split (0.2 means 20%).\n",
        "#\n",
        "# random_state:\n",
        "# A parameter that controls the shuffling applied to the data before applying the split, ensuring reproducibility.\n",
        "#\n",
        "# vectorizer:\n",
        "# A variable that stores an instance of CountVectorizer, which is used to convert a collection of text documents into a matrix of token counts.\n",
        "#\n",
        "# CountVectorizer:\n",
        "# A class from sklearn that converts a collection of text documents into a matrix of token counts, enabling numerical representation of text data.\n",
        "#\n",
        "# fit_transform:\n",
        "# A method that fits the vectorizer to the input data and transforms it into a numerical format in one step.\n",
        "#\n",
        "# transform:\n",
        "# A method that transforms new data into the same numerical format as the training data without fitting the vectorizer again.\n",
        "#\n",
        "# X_train_vectorized:\n",
        "# A variable that stores the vectorized representation of the training input features.\n",
        "#\n",
        "# X_test_vectorized:\n",
        "# A variable that stores the vectorized representation of the testing input features.\n",
        "\n"
      ],
      "metadata": {
        "id": "xl3rcshl2zeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# model:\n",
        "# A variable that stores an instance of the Multinomial Naive Bayes classifier, which will be used to train and make predictions on the data.\n",
        "#\n",
        "# MultinomialNB:\n",
        "# A class from the sklearn.naive_bayes module that implements the Naive Bayes algorithm specifically for multinomially distributed data, commonly used for text classification.\n",
        "#\n",
        "# fit:\n",
        "# A method that trains the model using the provided input features and target labels, adjusting the model parameters to minimize error.\n",
        "#\n",
        "# X_train_vectorized:\n",
        "# A variable that contains the vectorized representation of the training input features, which the model will use to learn from.\n",
        "#\n",
        "# y_train:\n",
        "# A variable that contains the target labels corresponding to the training input features, used for training the model.\n",
        "\n"
      ],
      "metadata": {
        "id": "3WfuP5iV2zhb",
        "outputId": "8887c679-d55a-4647-a00c-709bda4e6838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_vectorized)\n",
        "\n",
        "# y_pred:\n",
        "# A variable that stores the predicted sentiment labels for the test dataset, generated by the model.\n",
        "#\n",
        "# predict:\n",
        "# A method that takes new input features and returns the predicted target labels based on the model's learned parameters.\n",
        "#\n",
        "# model:\n",
        "# Refers to the trained Multinomial Naive Bayes classifier that has been fitted to the training data.\n",
        "#\n",
        "# X_test_vectorized:\n",
        "# A variable that contains the vectorized representation of the testing input features, which are used by the model to generate predictions.\n"
      ],
      "metadata": {
        "id": "3Iei5_lB2zkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix)\n",
        "\n",
        "# accuracy:\n",
        "# A variable that stores the proportion of correct predictions made by the model compared to the total number of predictions, expressed as a decimal.\n",
        "#\n",
        "# metrics:\n",
        "# A module in sklearn that provides various functions for evaluating the performance of machine learning models.\n",
        "#\n",
        "# accuracy_score:\n",
        "# A function from the metrics module that calculates the accuracy of the model by comparing the actual and predicted labels.\n",
        "#\n",
        "# confusion_matrix:\n",
        "# A variable that holds a matrix that summarizes the number of correct and incorrect predictions, categorized by class.\n",
        "#\n",
        "# confusion_matrix:\n",
        "# A function from the metrics module that computes the confusion matrix to evaluate the accuracy of a classification.\n",
        "#\n",
        "# print:\n",
        "# A built-in Python function that outputs data to the console.\n",
        "#\n",
        "# f-string:\n",
        "# A string formatting method in Python that allows embedding expressions inside string literals, prefixed by `f` or `F`, using curly braces `{}`.\n",
        "#\n",
        "# y_test:\n",
        "# A variable containing the true sentiment labels for the test dataset, used for comparison with predictions.\n",
        "#\n",
        "# y_pred:\n",
        "# A variable containing the predicted sentiment labels generated by the model for the test dataset.\n"
      ],
      "metadata": {
        "id": "C97Mu6N92znB",
        "outputId": "baad2791-8c2c-44ff-9a05-b8bed33e536e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.00\n",
            "Confusion Matrix:\n",
            "[[0 2]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        " text_vectorized = vectorizer.transform([text])\n",
        " prediction = model.predict(text_vectorized)\n",
        " return prediction[0]\n",
        "# Example usage\n",
        "new_text = \"I loved the plot and the acting!\"\n",
        "print(f'Sentiment: {predict_sentiment(new_text)}')\n",
        "\n",
        "# predict_sentiment:\n",
        "# A function defined to predict the sentiment of a given text input based on the trained model.\n",
        "#\n",
        "# text:\n",
        "# A parameter representing the input text for which sentiment needs to be predicted.\n",
        "#\n",
        "# text_vectorized:\n",
        "# A variable that holds the vectorized representation of the input text, prepared for input to the model.\n",
        "#\n",
        "# vectorizer:\n",
        "# The CountVectorizer instance that was fitted on the training data, used to convert text data into numerical format.\n",
        "#\n",
        "# transform:\n",
        "# A method that converts new text data into the same vectorized format used for training, allowing the model to process it.\n",
        "#\n",
        "# prediction:\n",
        "# A variable that stores the output from the model, which indicates the predicted sentiment for the input text.\n",
        "#\n",
        "# model:\n",
        "# Refers to the trained Multinomial Naive Bayes classifier used to make predictions.\n",
        "#\n",
        "# return:\n",
        "# A statement that exits the function and provides the specified value back to the caller.\n",
        "#\n",
        "# new_text:\n",
        "# A variable that holds a sample text for testing the sentiment prediction function.\n",
        "#\n",
        "# print:\n",
        "# A built-in Python function that outputs the specified message or variable to the console.\n",
        "#\n",
        "# f-string:\n",
        "# A string formatting method that allows embedding expressions within string literals, making it easier to create formatted output.\n"
      ],
      "metadata": {
        "id": "R2BKZbFq2zpc",
        "outputId": "b8b6c1fd-88b1-4668-968a-186023165329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFG_BTei2zry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpuvM0MkxMiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHI0ogXbvuGy"
      },
      "source": [
        "print(\"Hello World\")\n",
        "\n",
        "# print:\n",
        "# A built-in Python function used to display output to the console or standard output device.\n",
        "#\n",
        "# \"Hello World\":\n",
        "# A string literal that contains the text \"Hello World\", commonly used as a basic example in programming tutorials.\n",
        "#\n",
        "# \" \":\n",
        "# Quotation marks used to define the beginning and end of a string in Python.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvjJu5iNvuG1"
      },
      "source": [
        "This combination allows for the procution of beautiful documents containing software, documentation and discussion. For larger codes you may wish to use Python in a stand-alone environment such as a traditional IDE. But for demonstration purposes Jupyter is a very useful tool.\n",
        "\n",
        "Notebook files have the extension \".ipynb\" extension. A Jupyter notebook is one of many environments you may run Python code.  Colab and the Jupyter notebook editor in Anaconda are two of the many pieces of software you may use to write and run a Jupyter notebook. For this course we recommend using the online Google Colab tool, but you can use Anaconda to run the notebooks on your own machine within an internet connection. On college computers, Jupyter can be used by launchng Anaconda from the Software Hub Apps Anywhere interface.\n",
        "\n",
        "Note that exact interfaces will differ between different environments but the same functionality should be found in most environments. This course will be using the Colab environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br4ThcjVNBfb"
      },
      "source": [
        "## Cells and Executing Code\n",
        "\n",
        "A notebooks is made up of one or more \"cells\". Cells can contain the html-like text used to generate text or code to be run by the user. A cell containing a piece of code may be recognised by the the  ```[]```  to the left of it. Code in these blocks can be run in a nubmer of ways. The simplest is click on the ```[ ]``` . This will execute the code. Try this with the code snippet below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znQZKSLZvuG2"
      },
      "source": [
        "print(\"Yes, it worked!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX2A7djDvuG4"
      },
      "source": [
        "You should have seen the message \"Yes, it worked!\" appear immediately beneath the code. This is the output of the code, which has been printed to the screen. You may also have noticed a number appear between the square brackets to the left of the code snippet. This indicates the order in which the code snippet has been executed. Code cells may be executed in any order and variables will be saved between execution of code snippets. To try this, execute the three codes snippets below in the following order:\n",
        "- 1\n",
        "- 2\n",
        "- 3\n",
        "- 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAE233GJvuG4"
      },
      "source": [
        "a=\"Message 1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt9NlZYyvuG6"
      },
      "source": [
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZUIOI-ZvuG8"
      },
      "source": [
        "a=\"Message 2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCXAZCPzNUWr"
      },
      "source": [
        "The first time you ran code snippet 1 you should have seen \"Message 1\" as the output and the second time the output should have been \"Message 2\". This is because the first time it was run, the value assigned to the variable named \"a\" was \"Message\" as set by the first code snippet and the second time it was \"Message 2\" as set by the third code snippet. Note also the current numbers contained within square brackets. These help you to kno which cells have been executed and in which order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8YYhdP7NbjD"
      },
      "source": [
        "##Sharing Jupyter Notebooks on Colab\n",
        "When a Jupyter Notebook is shared with you on Colab, you will often receive access to the notebook which will alow you to run code, but not edit it. This should be the case for the notebooks that form part of this course. In this case you can select \"Save a Copy in Drive\" from the \"File\" menu to create a new copy that is yours and yo can edit.\n",
        "\n",
        "For this course, it is reccommended that you create two copies. One of these should be the original copy without your edits, and another which you can edit to compelte exercises or expierment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSpv_w2nvuG-"
      },
      "source": [
        "## Basic Jupyter Commands\n",
        "\n",
        "Jupyter contains a number of useful tools for executing these cells. By using the \"Runtime\" menu, you can run multiple cells at a time using \"Run all\", \"Run before\", \"Run selected\" and \"Run after\".\n",
        "\n",
        "You can clear output (this is the term for what is written under a code cell when it's executed) by clicking on the symbol to the left of it. You can clear all outputs from the notebook using the \"Clear All Outputs\" command on the \"Edit\" menu. Clearing the output will not unset variables set by the code snippets run, only remove the output printed to the screen.\n",
        "\n",
        "To unset variables, use the \"Restart Runtime\" or \"Reset Runtime\" option in the Runtime menu. The \"Interrupt Execution\" command on the kernel menu will halt the procesing of code, which can be useful if you've accidentally written a piece of code that will never finish executing or if the code is taking too long to execute.\n",
        "\n",
        "The \"insert\" menu allows you to create new cells. The \"cell type\" option in the \"cell\" menu allows you toggle the current cell type between the different cell types available:\n",
        "- **Code**: Code snippets\n",
        "- **Text**: The html-like language used to generate text, tables, equations, etc.\n",
        "\n",
        "Alternatively, you can hover your mouse in the space after a cell and add a code or text cell there.\n",
        "\n",
        "###Exercise\n",
        "\n",
        "Try each of these commands from the different menus for yourself on this  notebook and ensure they behave as you would expect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY8lQr8RNgnL"
      },
      "source": [
        "## Text Cells in Jupyter\n",
        "You can include all sort so information in Jupyter text cells to obtain different effects. To see how each of the following examples is generated, double click on this cell. To return to the formatted text, run the cell.\n",
        "\n",
        "### Headings\n",
        "Headings can be generated using the hash symbol \"#\". The more of these there are, the smaller the heading. The sub-sub-heading above is an example.\n",
        "\n",
        "### Tables\n",
        "Tables can be created in a way similar to basic html, using the a comabination of the \"|\" and \"-\" symbols:\n",
        "\n",
        "| This | is    |\n",
        "|------|-------|\n",
        "|   a  |  table|\n",
        "| It's | fancy |\n",
        "\n",
        "### Equations\n",
        "Equations can be written in a way similar to LaTeX by surrouding the text with \"\\$\" symbols:\n",
        "\n",
        "$a=\\frac{\\int\\limits_{0}^{\\pi} \\sin{(bx)} \\textrm{d}x}{4}$\n",
        "\n",
        "Don't worry if you don't understand the exact syntax used to generate this example. In your example of it in your exercise, try writing something very simple instead. If it looks like a simple algebraic expression, it will probably render how you intend.\n",
        "\n",
        "### Code Snippets\n",
        "You can write snippets of code in a text cell and they will be highlighted as if they were code written in a code cell. This can be useful for demonstrating a code feature in a textual way. For example:\n",
        "\n",
        "```python\n",
        "print (\"Hello World\")\n",
        "```\n",
        "\n",
        "There is not a way to run this code, it is merely normal text highlighted to look like code. The \"python\" which precedes the code itself tells Jupyter which language you are writing the code snippet in so it can be highlighted accorindly.\n",
        "\n",
        "In some environments, text cells may also be referred to as \"markdown\" cells.\n",
        "\n",
        "###Exercise\n",
        "Try creating simple versions of each of the constructs above in a new text cell below this one."
      ]
    }
  ]
}